---
title: Home
layout: home
nav_order: 1
---

# About Titanis
{: .fs-9 }

Titanis is an open-source library for Apache Spark that streamlines concept drift detection for machine learning pipelines. In addition to drift detection, Titanis comprises incremental machine learning algorithms optimized for online learning and distributed systems. Titanis is built on Apache Spark and supports the Spark Structured Streaming API, making it easy to integrate into existing Spark Streaming pipelines.

Titanis is built using Scala, which runs on the Java Virtual Machine. This not only enables native implementations of drift detection and machine learning algorithms to work with Spark Streaming, but also supports the usage of Java-implemented drift detectors and learners from the extensive library of MOA. This gives users of Titanis access to the wide range of algorithms already in place in MOA and makes it simpler to integrate MOA algorithms in existing Spark pipelines. The learning algorithms in Titanis are specially designed to work for streaming data in a distributed fashion using Apache Spark. Titanis trains, evaluates, and tests ML models and ensembles in a distributed manner, leveraging the fault-tolerant and scalable Apache Spark Structured Streaming engine.

Titanis has three distinguishing features. The first unique feature is the suite of drift detection methods provided in Titanis. There are two native methods and a wrapper for drift detection algorithms from MOA. This makes Titanis the sole and complete library for drift detection in Apache Spark. The second novel feature is the incremental and distributed machine learning algorithms. Titanis boasts a fully distributed and online lazy learning algorithm implementation and an ensemble algorithm. The learners are tested, evaluated, and trained in an online and distributed manner. This positions Titanis to fill the gap in the capabilities of existing machine learning libraries available for Apache Spark. Last but not least, the third differentiating factor of Titanis is the MOA wrapper. Titanis features a wrapper for both drift detectors and learners from MOA, the premier stream learning platform implemented in Java. The Scala-implemented wrappers enable Titanis to use algorithms from the extensive, community-built machine learning library. This showcases the versatility of Titanis and provides developers the opportunity to extend the project in multiple ways.

## Incremental Machine Learning Algorithms
{: .fs-7 }

## Titanis Architecture
{: .fs-7 }

![Titanis Workflow](./assets/Titanis%20Job%20Cycle.svg "Workflow of a Titanis learner")

The workflow of a Titanis learner is illustrated above. Any Titanis job starts with reading the data stream into the application as micro-batches, using the DataStreamReader provided in the Spark Structured Streaming API. The DataFrame is represented as an unbounded table within Spark, and each new instance is treated as an appended row to the unbounded table. In batch-wise processing mode, instances that arrive within certain trigger intervals are treated as micro-batches of the data stream. For Titanis, the trigger is file-based instead of time-based. This implies that the StreamReader is triggered whenever a new file arrives in an input directory. In the event that multiple files arrive at the input directory together, the files are read in the order of their arrival. The current version of Titanis only supports this method of reading the data stream. However, future versions will support more dynamic reading of data. 

When the file is read into a streaming DataFrame by the StreamReader, the data undergoes preprocessing. Each micro-batch of data is partitioned into n-sized partitions, where n is the number of workers in the cluster. Titanis is currently being tested in local mode, hence the value of n corresponds to the number of worker threads allotted to the Spark application. The order of arrival of the batches is preserved, so the first batch to arrive is preprocessed first. The preprocessing includes the filtering of null rows, renaming columns to standardized names, mapping nominal attributes to numeric values, adding helper columns, and assembling the vector of the predictor attributes. The preprocessing stage is fully distributed i.e., the partitions are preprocessed by the workers in parallel. There are no join operations for the preprocessing stage, so there is no shuffling of the data between the workers. After the preprocessing is completed, the partitions are then sent through to the learner.

The learners in Titanis rely on Spark StreamingQueries. Each of the learners have three crucial methods, namely predict, evaluate, and train, and each of these methods initiate their own StreamingQueries. A StreamingQuery in Spark is used for reading or writing streaming DataFrames. By default, StreamingQueries use the micro-batch processing engine. The learners in Titanis initiate three StreamingQueries simultaneously. These queries remain active until the final query i.e., the Training query is terminated. To begin the learning process, the preprocessed micro-batch is sent to the Prediction StreamingQuery, then the Evaluation, and lastly, the Training query. After this the input micro-batch of data is discarded, and the next batch is sent to the Prediction query. This process continues until no new micro-batches are observed for a given interval.

Since the queries are active simultaneously, the micro-batch of data is accessible to all queries simultaneously. However, this is what the scheduler class, Monitor, helps prevent. To fully utilize each of the data instances from the stream, the learners are first tested with the new data, then the results are evaluated, and finally, these instances are then used to train the learner. This method of evaluation is called interleaved-test-then-train or prequential evaluation. To ensure that the order of the stages is preserved, the Monitor uses triggers to signal to the StreamingQueries when they can begin processing the next micro-batch of data at their disposal. Hence, the Monitor plays a crucial role in ensuring that the results and the resulting model are accurate.

The Monitor plays another role in conjunction with scheduling the processing of the micro-batches. The Monitor listens to all the StreamingQueries. Hence, it is aware of when a micro-batch finishes a stage in the learning process. This awareness allows the Monitor to be used to output the intermittent results of each stage in the learning process to an output directory. The batch-wise results are split into three types. The first type is output after the prediction stage is completed. This output contains the instances of the micro-batch with a few additional columns, mainly, the prediction column, which records the prediction made by the learner. The second type of result is output after the evaluation stage. The evaluation metrics chosen for the learning task are computed and output. The final type of result is output after the training stage is finished. This output type may contain some information about the model that is being trained, but generally, the results for this type do not contain much information. All the results are in a CSV format and are provided in such manner to ease the usage of intermittent results in other forms of analysis.

The workflow presented is for the learning algorithms available in Titanis. For the concept drift detection methods, the workflow is only slightly different. Instead of the three StreamingQueries shown in the illustration, the drift detection workflow only comprises one StreamingQuery i.e., the detection query. The drift detectors work in standalone mode or in conjunction with other Spark applications. When in standalone mode, the reading and preprocessing stage occurs in the same way it does for the learner. When using the drift detector from another Spark application, the StreamingQuery can be invoked on its own as well.